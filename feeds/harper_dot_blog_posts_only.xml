<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0"><channel><title>Filtered: Harper Reed's Blog</title><link>https://harper.blog/</link><description>A filtered version of the feed from https://harper.blog/. Original content is attributed to the respective authors.</description><language>en-GB</language><pubDate>Thu, 24 Apr 2025 07:25:26 +0000</pubDate><attribution>This feed is a filtered version of the original feed available at https://harper.blog/. All content is attributed to the original author(s).</attribution><item><title>An LLM Codegen Hero's Journey</title><link>https://harper.blog/2025/04/17/an-llm-codegen-heros-journey/</link><description>&lt;p&gt;I have spent a lot of time since my &lt;a href="https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/"&gt;blog post&lt;/a&gt; about my LLM workflow talking to folks about codegen and how to get started, get better, and why it is interesting.&lt;/p&gt;
&lt;p&gt;There has been an incredible amount of energy and interest in this topic. I have received a ton of emails from people who are working to figure all of this out. I started to notice that many people are struggling to figure out how to start, and how it all fits together. Then I realized that I have been hacking on this process since 2023 and I have seen some shit. Lol.&lt;/p&gt;
&lt;p&gt;I was talking about this with friends (Fisaconites&amp;rsquo;s represent) and I sent this message in response to a thread about AI assisted agents, and editors:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;if i were starting out, i don&amp;rsquo;t know if it is helpful to jump right into the &amp;ldquo;agent&amp;rdquo; coders. It is annoying and weird. having walked a few people through this (successfully, and not successfully) I find that the &amp;ldquo;hero&amp;rsquo;s journey&amp;rdquo; of starting with the Copilot, moving to the copy and paste from Claude web, to the Cursor/continue, to the fully automated &amp;ldquo;agents&amp;rdquo; seems to be a successful way to adopt these things.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This lead me to start thinking a lot about the journey and how to get started using agentic coding:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The caveat is that this is largely for people with experience. If you don’t have much dev experience, then fuck it - jump to the end. &lt;strong&gt;Our brains are often ruined by the rules of the past.&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id="a-journey-of-sight-and-sound"&gt;A journey of sight and sound&lt;/h2&gt;





















  
  
  


  
  
    
    
      
    

    


    
    


    
    
    
    
      
      
    
    
    
    


    
    
      
      

      


      

      
      
        
        
        
      
      
      
      

    
    

    
    
      &lt;figure class=""&gt;
      
          &lt;img alt="Harper is very trustworthy" class="img " height="768" src="https://harper.blog/2025/04/17/an-llm-codegen-heros-journey/journey-harper_hu_150720cd34953896.webp" title="" width="1024" /&gt;
      
        &lt;figcaption class="caption-Your-thoughtful-guide-Harper-iPhone-X-6102018" id="caption-Your thoughtful guide: Harper. iPhone X, 6/10/2018"&gt;
          Your thoughtful guide: Harper. iPhone X, 6/10/2018
        &lt;/figcaption&gt;
      &lt;/figure&gt;
    

  
  






  


&lt;p&gt;This is my journey. It is largely the path I took. I think you could speed run it if you were compelled. I don’t think you need to follow every step, but I do think every step is additive.&lt;/p&gt;
&lt;p&gt;Here are the steps:&lt;/p&gt;
&lt;h3 id="step-1-get-out-of-bed-with-wonder-and-optimism"&gt;Step 1: Get out of bed with wonder and optimism&lt;/h3&gt;
&lt;p&gt;Lol. Just kidding. Who has time for that? It may help, but the world is falling apart and all we got is codegen to distract us.&lt;/p&gt;
&lt;p&gt;It does help to assume that these type of workflows could work and could be additive. If you hate LLMs and don’t think it will work, then you will not be successful here. ¯\_(ツ)_/¯&lt;/p&gt;
&lt;h3 id="step-2-start-with-ai-assisted-autocomplete"&gt;Step 2: Start with AI-assisted autocomplete&lt;/h3&gt;
&lt;p&gt;This is the real step one! You need to spend enough time in the IDE context to know how well you would work with &lt;a href="https://en.wikipedia.org/wiki/Code_completion"&gt;intellisense&lt;/a&gt;, &lt;a href="https://zed.dev/blog/out-of-your-face-ai"&gt;zed autocomplete&lt;/a&gt;, &lt;a href="https://copilot.github.com/"&gt;Copilot&lt;/a&gt;, etc. It gives you an idea of how the LLM is working - and prepares you for the stupid shit it will often recommend.&lt;/p&gt;
&lt;p&gt;People seem to want to skip this step and just jump to the end. Then they are like “this LLM is a piece of shit and can’t do anything right!” Which is not accurate, but also can be true. The magic is in the nuance. Or as I like to remember: &lt;em&gt;life is confusing&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id="step-3-start-using-copilot-as-more-than-autocomplete"&gt;Step 3: Start using Copilot as more than autocomplete&lt;/h3&gt;
&lt;p&gt;Once you have a good process in place with the autocomplete and you are not mad &lt;em&gt;all&lt;/em&gt; of the time, you can move on to the magic of talking to Copilot.&lt;/p&gt;
&lt;p&gt;VS Code has a pane where you can Q&amp;amp;A with Copilot and it will help you with your code, etc. It is pretty cool. You can have a nice convo about your code, and it will be thoughtful and help you solve whatever query you asked.&lt;/p&gt;
&lt;p&gt;However, using Copilot is like using a time machine to talk to ChatGPT in 2024. It isn’t &lt;em&gt;that&lt;/em&gt; great.&lt;/p&gt;
&lt;p&gt;You will be wanting more.&lt;/p&gt;
&lt;h3 id="step-4-move-to-copying-and-pasting-code-into-claude-or-chatgpt"&gt;Step 4: Move to copying and pasting code into Claude or ChatGPT&lt;/h3&gt;
&lt;p&gt;You start to satisfy your curiosity by pasting code into the browser based foundational model and asking “WHY CODE BROKE??” And then having LLM respond with a coherent and helpful response.&lt;/p&gt;
&lt;p&gt;You will be AMAZED! The results are going to blow your mind. You are going to start to build lots of weird shit, and doing really fun things with code again. Mostly cuz it cut out the entire debugging process.&lt;/p&gt;
&lt;p&gt;You can also do wild things like paste in a Python script and tell the LLM “make this into go” and it will just &lt;em&gt;make it into go&lt;/em&gt;. You will start thinking “I wonder if I can one shot this.”&lt;/p&gt;
&lt;p&gt;Copilot will start to look like 2004 autocomplete. It is handy, but not really necessary.&lt;/p&gt;
&lt;p&gt;This will lead you down a couple sub paths:&lt;/p&gt;
&lt;h4 id="you-will-start-to-prefer-one-model-cuz-of-vibes"&gt;You will start to prefer one model cuz of vibes&lt;/h4&gt;
&lt;p&gt;This is the unfortunate first step towards the vibe in vibe coding. You will start to prefer how one of the big models talk to you. It is feelings tho. Kind of weird. You will find yourself thinking “I like how Claude makes me feel.”&lt;/p&gt;
&lt;p&gt;Many developers seem to like Claude. I use both, but mostly Claude for code related things. The vibe with Claude is just better.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You have to pay for them to get the good stuff. So many friends are like “This is a piece of shit” and then you find out they are using a free model that barely works. Lol. This was more of an issue when the free version was ChatGPT 3.5, but make sure you are using a capable model before you throw the entire premise out.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id="you-will-start-thinking-about-how-to-make-things-go-faster"&gt;You will start thinking about how to make things go faster&lt;/h4&gt;
&lt;p&gt;After copying and pasting code into Claude for a few weeks you are going to realize that this is annoying. You are going to start working through context packing, and trying to fit more of your code into the LLM context window.&lt;/p&gt;
&lt;p&gt;You will experiment with &lt;a href="https://repomix.com/"&gt;repomix&lt;/a&gt;, &lt;a href="https://github.com/donoceidon/repo2txt"&gt;repo2txt&lt;/a&gt;, and other code context tools. Just so that you can slam your entire codebase into the Claude context window. There is a chance that you will even start writing shell scripts (well Claude will write them) to help make this process easier.&lt;/p&gt;
&lt;p&gt;This is a turning point.&lt;/p&gt;
&lt;h3 id="step-5-use-an-ai-enabled-ide-cursor-windsurf-"&gt;Step 5: Use an AI enabled IDE (Cursor, Windsurf? )&lt;/h3&gt;
&lt;p&gt;Then a friend will say “why don’t you just use &lt;a href="https://cursor.sh/"&gt;Cursor&lt;/a&gt;?”&lt;/p&gt;
&lt;p&gt;It will completely blow your mind. All the magic you just experienced by copying and pasting is now available in your IDE. It is faster, it is fun, and it is close to magic.&lt;/p&gt;
&lt;p&gt;At this point you are paying for like 5 different LLMs - what is another $20 a month.&lt;/p&gt;
&lt;p&gt;It works super well, and you feel way way more productive.&lt;/p&gt;
&lt;p&gt;You will start playing with the agentic coding features built directly into the editors. It will &lt;em&gt;basically&lt;/em&gt; work. But you can see a destination on the horizon that may be better.&lt;/p&gt;
&lt;h3 id="step-6-you-start-planning-before-you-code"&gt;Step 6: You start planning before you code&lt;/h3&gt;
&lt;p&gt;Suddenly you find yourself building out very robust specs, PRDs, and to-do docs that you can pipe into the IDEs agent, or into Claude web.&lt;/p&gt;
&lt;p&gt;You have never “written” so much documentation. You start to use other LLMs to write more robust documentation. You are transposing docs from one context (PRD) to another (“Can you make this into prompts”). You start to use the LLM to design your codegen prompts.&lt;/p&gt;
&lt;p&gt;You are saying the word “&lt;a href="https://en.wikipedia.org/wiki/Waterfall_model"&gt;waterfall&lt;/a&gt;” with a lot less disdain. If you are old, you may be fondly remembering the late 90s and early 2000s and wonder “is this what Martin Fowler felt like before &lt;a href="https://en.wikipedia.org/wiki/Agile_software_development"&gt;2001&lt;/a&gt;?”&lt;/p&gt;
&lt;p&gt;In the world of codegen: The spec is the &lt;a href="https://en.wikipedia.org/wiki/Godhead"&gt;godhead&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="step-7-you-start-playing-with-aider-to-enable-quicker-loops"&gt;Step 7: You start playing with aider to enable quicker loops&lt;/h3&gt;
&lt;p&gt;At this point you are ready to start getting into the &lt;strong&gt;good stuff&lt;/strong&gt;. The codegen previously required you to be involved, and paying attention. But it is 2025! Who wants to code with their fingers?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;One other path that lots of friends are experimenting with is to code with your voice. To start instruct aider via a whisper client. It is hilarious and fun. MacWhisper is a very good tool for this locally. Aqua, and superwhisper are nice but cost more. They may use cloud services to do the inference. I prefer local.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Trying out aider is a wild experience. You start it up, it instantiates itself into your project. You put your query directly into aider, and it just kind of does what you asked. It asks for permission to act, and gives you a framework to get things done, and then acts. It completes the task, and the commits to your repository. You no longer are so worried about one shotting tasks. you will just have aider do it in a few steps.&lt;/p&gt;
&lt;p&gt;You start building out rulesets for the LLM to follow. You learn about the “&lt;a href="https://www.reddit.com/r/cursor/comments/1joapwk/comment/mkqg8aw/"&gt;Big Daddy&lt;/a&gt;” rule, or the “no deceptions” addition to your prompts. You start be really good at prompting the robot.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It works.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Eventually you don’t even open up an IDE - you are just a terminal jockey now.&lt;/p&gt;
&lt;p&gt;You spend your time watching the robot do your job.&lt;/p&gt;
&lt;h3 id="step-8-you-lean-all-the-way-into-agentic-coding"&gt;Step 8: You lean all the way into agentic coding&lt;/h3&gt;
&lt;p&gt;You are now using an agent to code for you. The results are pretty good. There are a few times when you have no idea what’s going on. But then you remember you can just ask it.&lt;/p&gt;
&lt;p&gt;You start to experiment with &lt;a href="https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview"&gt;Claude Code&lt;/a&gt;, &lt;a href="https://cline.bot/"&gt;Cline&lt;/a&gt;, etc. You are super happy to be able to use a reasoning model (&lt;a href="https://aws.amazon.com/bedrock/deepseek/"&gt;deepseek&lt;/a&gt;!) and a coding model (&lt;a href="https://www.anthropic.com/claude/sonnet"&gt;Claude sonnet 3.7&lt;/a&gt;) together to start removing planning steps.&lt;/p&gt;
&lt;p&gt;You are doing wild stuff like running 3-5 concurrent sessions. Just tabbing through terminals watching robots code.&lt;/p&gt;
&lt;p&gt;You will start coding defensively:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;really hardcore test coverage&lt;/li&gt;
&lt;li&gt;thinking about &lt;a href="https://github.com/formal-land/coq-of-rust"&gt;formal verification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;using memory safe languages&lt;/li&gt;
&lt;li&gt;choosing languages based on compiler verbosity to help pack the context window&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You will think long and hard about how to make sure that the thing you are building just gets built, safely without intervention.&lt;/p&gt;
&lt;p&gt;You will spend &lt;strong&gt;SO&lt;/strong&gt; much money on tokens. You will also use up all your GitHub action hours running all the wild tests that you are running to make sure that the code is built safely.&lt;/p&gt;
&lt;p&gt;It feels good. You are not mad about not coding.&lt;/p&gt;
&lt;h3 id="step-9-you-let-the-agent-code-and-you-play-video-games"&gt;Step 9: You let the agent code, and you play video games&lt;/h3&gt;
&lt;p&gt;Suddenly, you are there. You are at the destination. Well, kind of - but you see where we are going. You start to worry about software jobs. Your friends are being laid off, and they can’t get new jobs. It feels different this time around.&lt;/p&gt;
&lt;p&gt;When you talk to your peers they think of you as a religious zealot cuz you are working within a different context than they are. You tell them “omg you have to try out agentic coding!” Maybe you add “I hate the word agentic” just to show that you have not drank 200 gallons of kool-aid. But you have. The world seems brighter cuz you are so productive with your code.&lt;/p&gt;
&lt;p&gt;It doesn’t matter. The paradigm has shifted. Kuhn could write a book about the confusion happening during this time.&lt;/p&gt;
&lt;p&gt;Nobody can see this because they didn’t go through the journey to get here. But those who have are agreeing and sharing their own tips around the journey, and debating the destination.&lt;/p&gt;
&lt;p&gt;Now that you are knee-deep in letting robots do the work, you can really focus on all those gameboy games you have been wanting to play. There is a lot of downtime. And when the robot is done with a task, it will ask “should I continue” and you type &lt;strong&gt;yes&lt;/strong&gt; and go back to Tetris.&lt;/p&gt;
&lt;p&gt;Very strange. Unsettling, even.&lt;/p&gt;
&lt;h2 id="the-acceleration"&gt;The acceleration&lt;/h2&gt;






















  
  
  


  
  
    
    
      
    

    


    
    


    
    
    
    
      
      
    
    
    
    


    
    
      
      

      


      

      
      
        
        
        
      
      
      
      

    
    

    
    
      &lt;figure class=""&gt;
      
          &lt;img alt="Confetti" class="img " height="1024" src="https://harper.blog/2025/04/17/an-llm-codegen-heros-journey/journey-confetti_hu_5c5b1e98a71e8689.webp" title="" width="1024" /&gt;
      
        &lt;figcaption class="caption-Confetti-at-a-Paul-McCartney-Concert-at-the-Tokyo-Dome-iPhone-6-4252015" id="caption-Confetti at a Paul McCartney Concert at the Tokyo Dome. iPhone 6, 4/25/2015"&gt;
          Confetti at a Paul McCartney Concert at the Tokyo Dome. iPhone 6, 4/25/2015
        &lt;/figcaption&gt;
      &lt;/figure&gt;
    

  
  







&lt;p&gt;I don’t know what will happen in the &lt;a href="https://ai-2027.com/"&gt;future&lt;/a&gt;. I am worried that people who are not working through this journey are not going to be attractive to &lt;a href="https://x.com/tobi/status/1909231499448401946"&gt;employers&lt;/a&gt;. Which is kind of near-sighted, because, ultimately, we are talking about tooling, and automation.&lt;/p&gt;
&lt;p&gt;When we were ramping up hiring in the past, we would often spread our queries well past our network, and past our tech stack. We would be a Python shop and interview people who didn’t know Python, and have never used Python. Our thought was that with a great engineer, we could work together to get them comfortable with Python. They would be additive even if they were not super comfortable with our stack. This worked out well for us. We hired incredible people who had never worked with our stack. Many times they brought such a different perspective that it elevated the entire team.&lt;/p&gt;
&lt;p&gt;The same principles apply to AI-assisted development. When hiring talented developers who match your team&amp;rsquo;s culture and show enthusiasm, their experience level with AI tools shouldn&amp;rsquo;t be a deal-breaker. Not everyone needs to be an AI development expert from day one. Instead, guide them through the learning process at their own pace while they work alongside more experienced team members.&lt;/p&gt;
&lt;p&gt;Eventually they will be the driver and will be successfully using these tools.&lt;/p&gt;
&lt;p&gt;One other aspect I keep thinking about: Writing skills have become critical. While we&amp;rsquo;ve always valued strong communicators on tech teams for documentation and collaboration, it&amp;rsquo;s doubly important now. Not only do you need to communicate with humans, you need to write clear, precise instructions for AI. Being able to craft effective prompts is becoming as vital as writing good code.&lt;/p&gt;
&lt;h2 id="the-leadership"&gt;The leadership&lt;/h2&gt;
&lt;p&gt;I think all leaders and engineering managers need to dive deep into AI-assisted development, whether you&amp;rsquo;re a believer or not. Here&amp;rsquo;s why: The next generation of developers you&amp;rsquo;ll be hiring will have learned to code primarily through AI tools and agents. This is what software engineering is becoming. We need to understand and adapt to this reality.&lt;/p&gt;
&lt;p&gt;Us code boomers are not long for this world.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;interesting note:&lt;/strong&gt; i don&amp;rsquo;t really use LLMs to help me write things. I imagine they would be good at it, but i find that i want my voice to be heard, and not normalized. Whereas my code needs to be normalized. interesting.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Thanks to Jesse, Sophie, the Vibez crew (Erik, Kanno, Braydon, and others), team 2389, and everyone else who gave me feedback on this post.&lt;/p&gt;

                                &lt;figure&gt;
                                    &lt;img alt="journey-confetti.webp" height="1024" src="https://harper.blog/2025/04/17/an-llm-codegen-heros-journey/journey-confetti.webp" width="1024" /&gt;
                                    
                                &lt;/figure&gt;
                                &lt;figure&gt;
                                    &lt;img alt="journey-harper.webp" height="768" src="https://harper.blog/2025/04/17/an-llm-codegen-heros-journey/journey-harper.webp" width="1024" /&gt;
                                    
                                &lt;/figure&gt;
                        
                        &lt;hr /&gt;
                        &lt;p&gt;Thank you for using RSS. I appreciate you. &lt;a href="mailto:harper&amp;#64;modest.com"&gt;Email me&lt;/a&gt;&lt;/p&gt;</description><pubDate>Thu, 17 Apr 2025 09:00:00 -0500</pubDate></item><item><title>Now @ 04-17-2025</title><link>https://harper.blog/now/2025-04-17/</link><description>&lt;h2 id="and-we-are-off"&gt;And we are off..&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;This company is started.&lt;/li&gt;
&lt;li&gt;We have raised some money from amazing people.&lt;/li&gt;
&lt;li&gt;I am excited to be building things again.&lt;/li&gt;
&lt;li&gt;Thinking a lot about what I want &lt;a href="https://2389.ai"&gt;2389 Research&lt;/a&gt; to turn into.&lt;/li&gt;
&lt;li&gt;I can&amp;rsquo;t wait to show you what we are building.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="the-weird"&gt;The weird&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;I am still feeling a deep sense of uncertainty.&lt;/li&gt;
&lt;li&gt;AI is coming for us faster than we thought.&lt;/li&gt;
&lt;li&gt;I don&amp;rsquo;t think people my age who are being laid off now are going to be able to find jobs equivalent to what they had before.&lt;/li&gt;
&lt;li&gt;The state of the US is very concerning at the moment.&lt;/li&gt;
&lt;/ul&gt;





















  
  
    
    &lt;img alt="" class="img   " height="" src="https://harper.blog/images/posts/worse.jpg" title="" width="" /&gt;
  
  






  


&lt;h3 id="the-normal"&gt;The normal&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Reading a lot of books. Send me your recs.&lt;/li&gt;
&lt;li&gt;Started bringing my camera everywhere, again. Come get your photo taken.&lt;/li&gt;
&lt;li&gt;Trying to meet people out and about. HMU. let&amp;rsquo;s get lunch&lt;/li&gt;
&lt;li&gt;Running is fun. Ugh. Very much type 2 fun.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="working-on-a-lot-of-tech-projects"&gt;Working on a lot of tech projects&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;I am an AI assistant.&lt;/li&gt;
&lt;li&gt;Trying to blog a lot more and at a regular cadence. Now with &lt;a href="https://harper.blog/notes/"&gt;notes&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Pretty excited about Bluesky and atproto specifically. Very neat.&lt;/li&gt;
&lt;li&gt;&lt;del&gt;I really want to merge my photos, writing, and read books into a single website. Thinking a lot about that. Give me ideas&lt;/del&gt; I think I am making progress! Now just need to figure out photos.&lt;/li&gt;
&lt;li&gt;Still, excited about the future. Although a bit worried about the present.&lt;/li&gt;
&lt;/ul&gt;

                        
                        &lt;hr /&gt;
                        &lt;p&gt;Thank you for using RSS. I appreciate you. &lt;a href="mailto:harper&amp;#64;modest.com"&gt;Email me&lt;/a&gt;&lt;/p&gt;</description><pubDate>Thu, 17 Apr 2025 00:00:00 -0500</pubDate></item><item><title>Waterfall in 15 Minutes or Your Money Back</title><link>https://harper.blog/2025/04/10/waterfall-in-15-minutes-or-your-money-back/</link><description>&lt;p&gt;I recently had a conversation with a friend that started out as a casual catch-up and spiraled into a deep exploration of AI-assisted coding and what it&amp;rsquo;s doing to our workflows, teams, and sense of &amp;ldquo;craft.&amp;rdquo; It spanned everything from rewriting old codebases to how automated test coverage changes the nature of programming.&lt;/p&gt;
&lt;p&gt;I took the transcript from granola, popped it into o1-pro, and asked it to write this blog post. Not terrible. Representative of my beliefs.&lt;/p&gt;
&lt;p&gt;I sent it to a few friends, and they all were interested in sending it to a few more friends. That means I gotta publish it. So here goes!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;this is a good reminder that if you get an email from someone and the writing is perfect and has no affectation - an AI probably wrote it. lol.&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2 id="waterfall-in-15-minutes-or-your-money-back"&gt;Waterfall in 15 Minutes or Your Money Back&lt;/h2&gt;
&lt;h3 id="the-new-normal-why-does-code-quality-even-matter"&gt;The New Normal: &amp;ldquo;Why Does Code Quality Even Matter?&amp;rdquo;&lt;/h3&gt;
&lt;p&gt;For years, we&amp;rsquo;ve talked about code as craft—how we get into that precious flow state, sculpt a piece of logic, and emerge victorious, artisanal bug fixes in hand. But there&amp;rsquo;s a new paradigm creeping in where code generation tools (think large language models, or LLMs) can effectively pump out features in minutes.&lt;/p&gt;
&lt;p&gt;Some folks are rattled by this pace and how it upends the old standards of &amp;ldquo;clean code.&amp;rdquo; Suddenly, writing robust test suites, or even test-driven development, is more about letting the bots verify themselves than it is about methodically stepping through each line of code.&lt;/p&gt;
&lt;p&gt;Will code quality nosedive? Possibly. On the other hand, we&amp;rsquo;re also seeing a push for hyper-defensive coding—static analysis, formal verification, and test coverage everywhere—so that if an AI-based agent does break something, we catch it quickly. We&amp;rsquo;ve never needed top-notch CI/CD pipelines and rigorous checks more than we do now.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 id="waterfall-in-15-minutes"&gt;Waterfall in 15 Minutes&lt;/h3&gt;





















  
  
  


  
  
    
    
      
    

    


    
    


    
    
    
    
      
      
    
    
    
    


    
    
      
      

      


      

      
      
        
        
        
      
      
      
      

    
    

    
    
      &lt;figure class=""&gt;
      
          &lt;img alt="Waterfall" class="img " height="1024" src="https://harper.blog/2025/04/10/waterfall-in-15-minutes-or-your-money-back/waterfall_hu_60c8753e36607622.webp" title="" width="1024" /&gt;
      
        &lt;figcaption class="caption-Iceland-has-a-lot-of-waterfalls-Leica-Q-9302016" id="caption-Iceland has a lot of waterfalls. Leica Q, 9/30/2016"&gt;
          Iceland has a lot of waterfalls. Leica Q, 9/30/2016
        &lt;/figcaption&gt;
      &lt;/figure&gt;
    

  
  






  


&lt;p&gt;We used to talk about &amp;ldquo;Waterfall vs. Agile&amp;rdquo; as if they were moral opposites, with Agile the only correct path. But ironically, code generation is nudging us toward micro waterfall cycles: we carefully define a spec (because the AI needs clarity), press &amp;ldquo;go,&amp;rdquo; wait for the code to be generated, and review. It might still feel iterative, but in practice, we do a chunk of planning, then a chunk of execution, then a chunk of review. &amp;ldquo;Waterfall in 15 minutes.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;The real magic? You can spin up multiple &amp;ldquo;agents&amp;rdquo; simultaneously. While one AI is building a feature, another is handling your docs, and a third is chewing on your test coverage. That&amp;rsquo;s not exactly the old idea of a single, linear Waterfall—this is concurrency on steroids.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 id="the-coming-shift-in-team-culture"&gt;The Coming Shift in Team Culture&lt;/h3&gt;
&lt;p&gt;If you manage or lead an engineering team, you probably hear from the top: &amp;ldquo;What about AI to make us more productive?&amp;rdquo; But you may also sense that your existing team has varying levels of enthusiasm for these tools. Some are all-in—spinning up entire new features purely through prompt-driven coding—while others are protective of that craft identity.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s what I think works:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Run Small Pilots&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Pick an internal project, or maybe a side tool that doesn&amp;rsquo;t carry heavy production risk, and let a few curious engineers run wild with AI coding. Let them break stuff, experiment, see what happens when they trust the model a little too much, then watch how they incorporate best practices to rein it back in.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Rotate People In and Out&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Having a dedicated &amp;ldquo;AI-coded&amp;rdquo; side project means you can rotate team members—let them spend a week or two living in this new environment, learning from each other, and then bring those lessons back to the larger codebase.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Get Serious About Documentation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;AI &amp;ldquo;agents&amp;rdquo; often require extremely clear specs. Code generation is cheap, but guiding an LLM in the right direction costs careful planning. If you want your entire team to benefit, put the best specs and architecture docs you&amp;rsquo;ve ever written into a shared repository. You&amp;rsquo;ll thank yourself when people rotate on or off that project.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;h3 id="why-flow-state-may-be-overrated"&gt;Why Flow State May Be Overrated&lt;/h3&gt;
&lt;p&gt;One surprising takeaway: a lot of us got into coding because we love the flow state—the pure, heads-down, &amp;ldquo;zone&amp;rdquo; feeling. But AI coding doesn&amp;rsquo;t always foster that same immersion. You might spend an hour setting up prompts, letting the AI build stuff in the background, and occasionally popping over to approve or nudge it.&lt;/p&gt;
&lt;p&gt;For some folks, that&amp;rsquo;s jarring. For others—especially those who have kids or who juggle a million tasks—it&amp;rsquo;s liberating. When you can context-switch (check the AI&amp;rsquo;s output, jump back to real life, then come back to a functioning snippet), you realize there&amp;rsquo;s a new way to be productive that doesn&amp;rsquo;t revolve around long blocks of quiet time.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 id="does-this-mean-peak-programmer"&gt;Does This Mean &amp;ldquo;Peak Programmer?&amp;rdquo;&lt;/h3&gt;
&lt;p&gt;There&amp;rsquo;s chatter that once AI can generate code, we&amp;rsquo;ve hit &amp;ldquo;peak programmer&amp;rdquo;—that soon we won&amp;rsquo;t need as many engineers. That might be partly true if we&amp;rsquo;re talking about straightforward feature work or hooking up an API. But there are new complexities, too, around security, compliance, test coverage, and architecture.&lt;/p&gt;
&lt;p&gt;The real difference? &amp;ldquo;Strategic engineers&amp;rdquo; will flourish—those who can orchestrate multiple AI tools, keep an eye on code quality, and design new systems that scale. The folks who thrive will be part product manager, part architect, part QA, part developer. They&amp;rsquo;ll shape the prompts, define the tests, maintain quality, and handle all the edge cases an LLM doesn&amp;rsquo;t predict.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3 id="pro-tips-from-the-front-lines"&gt;Pro Tips from the Front Lines&lt;/h3&gt;
&lt;p&gt;A few things I&amp;rsquo;ve personally learned the hard way:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Start Manually, Then Turn On the AI&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For iOS apps, initialize the project in Xcode first, so the auto-generated files don&amp;rsquo;t confuse the AI. Then let the AI fill in the rest.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Short, Clear Prompts Sometimes Outperform Long Instructions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Oddly, telling an LLM &amp;ldquo;make code better&amp;rdquo; can work as well as a super-elaborate prompt. Experiment—some models respond better to fewer constraints.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Use a &amp;ldquo;Checkpoint&amp;rdquo; Workflow&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Commit often, even if it&amp;rsquo;s &amp;ldquo;Commit –m &amp;lsquo;It passed the tests, I guess!&amp;rsquo;&amp;rdquo; AI can break everything just as quickly as it can fix it. Frequent commits give you easy rollback points.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prevent AI from Over-Testing the Basics&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;AI loves to test everything, including whether a &lt;code&gt;for&lt;/code&gt; loop still loops. Stay vigilant, prune pointless tests, and keep your pipeline lean.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Document Absolutely Everything&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let the AI generate big &amp;ldquo;Implementation Guides.&amp;rdquo; These guides not only help you but help the AI itself on subsequent passes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;h3 id="final-thoughts"&gt;Final Thoughts&lt;/h3&gt;





















  
  
  


  
  
    
    
      
    

    


    
    


    
    
    
    
      
      
    
    
    
    


    
    
      
      

      


      

      
      
        
        
        
      
      
      
      

    
    

    
    
      &lt;figure class=""&gt;
      
          &lt;img alt="Road to the future" class="img " height="576" src="https://harper.blog/2025/04/10/waterfall-in-15-minutes-or-your-money-back/waterfall-road_hu_b129af1fabf9cd2a.webp" title="" width="1024" /&gt;
      
        &lt;figcaption class="caption-Road-to-the-future-Colorado-is-flat-Leica-Q-5142016" id="caption-Road to the future. Colorado is flat. Leica Q, 5/14/2016"&gt;
          Road to the future. Colorado is flat. Leica Q, 5/14/2016
        &lt;/figcaption&gt;
      &lt;/figure&gt;
    

  
  







&lt;p&gt;Our industry is shifting faster than it ever has. Some of our well-worn assumptions—like the centrality of the flow state, or big celebrations around meticulously hand-coded features—are about to look quaint. But that doesn&amp;rsquo;t mean we lose our creativity. Instead, it becomes about strategic orchestration—knowing what to build, how to describe it, and how to keep it from turning into a dumpster fire.&lt;/p&gt;
&lt;p&gt;In the end, we might see that what makes your product win isn&amp;rsquo;t brute-forcing code. It&amp;rsquo;s designing an experience users love. Because if we can spin up 10 versions of Instagram in a weekend, the tiebreaker won&amp;rsquo;t be how elegantly the code is written. It&amp;rsquo;ll be which one resonates with people—and that&amp;rsquo;s a design and product problem, not purely an engineering one.&lt;/p&gt;
&lt;p&gt;So welcome to the new waterfall—done in 15-minute cycles, with AI as your infinite junior engineer and your code pipeline on hyperdrive. It&amp;rsquo;s weird and wonderful and occasionally terrifying. And odds are, we&amp;rsquo;re all going to have to learn this dance one way or another.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;What a funny world we live in. I think things are going to continue to get weird. Let&amp;rsquo;s dig in&lt;/em&gt;&lt;/p&gt;

                                &lt;figure&gt;
                                    &lt;img alt="waterfall-road.jpg" height="3357" src="https://harper.blog/2025/04/10/waterfall-in-15-minutes-or-your-money-back/waterfall-road.jpg" width="5972" /&gt;
                                    
                                &lt;/figure&gt;
                                &lt;figure&gt;
                                    &lt;img alt="waterfall-road.webp" height="576" src="https://harper.blog/2025/04/10/waterfall-in-15-minutes-or-your-money-back/waterfall-road.webp" width="1024" /&gt;
                                    
                                &lt;/figure&gt;
                                &lt;figure&gt;
                                    &lt;img alt="waterfall.jpg" height="3654" src="https://harper.blog/2025/04/10/waterfall-in-15-minutes-or-your-money-back/waterfall.jpg" width="3654" /&gt;
                                    
                                &lt;/figure&gt;
                                &lt;figure&gt;
                                    &lt;img alt="waterfall.webp" height="1024" src="https://harper.blog/2025/04/10/waterfall-in-15-minutes-or-your-money-back/waterfall.webp" width="1024" /&gt;
                                    
                                &lt;/figure&gt;
                        
                        &lt;hr /&gt;
                        &lt;p&gt;Thank you for using RSS. I appreciate you. &lt;a href="mailto:harper&amp;#64;modest.com"&gt;Email me&lt;/a&gt;&lt;/p&gt;</description><pubDate>Thu, 10 Apr 2025 00:00:00 -0500</pubDate></item><item><title>My LLM codegen workflow atm</title><link>https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/</link><description>&lt;p&gt;&lt;em&gt;tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought &amp;ldquo;oh boy. how much time do you have!&amp;rdquo; and thus this post.&lt;/p&gt;
&lt;p&gt;(p.s. if you are an AI hater - scroll to the end)&lt;/p&gt;
&lt;p&gt;I talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.&lt;/p&gt;
&lt;p&gt;Here is my workflow. It is built upon my own work, conversations with friends (thx &lt;a href="https://www.nikete.com/"&gt;Nikete&lt;/a&gt;, &lt;a href="https://nocruft.com/"&gt;Kanno&lt;/a&gt;, &lt;a href="https://fsck.com/"&gt;Obra&lt;/a&gt;, &lt;a href="https://github.com/KristopherKubicki"&gt;Kris&lt;/a&gt;, and &lt;a href="https://thinks.lol/"&gt;Erik&lt;/a&gt;), and following many best practices shared on the various terrible internet &lt;a href="https://news.ycombinator.com/"&gt;bad&lt;/a&gt; &lt;a href="https://twitter.com"&gt;places&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is working well &lt;strong&gt;NOW&lt;/strong&gt;, it will probably not work in 2 weeks, or it will work twice as well. ¯\_(ツ)_/¯&lt;/p&gt;
&lt;h2 id="lets-go"&gt;Let’s go&lt;/h2&gt;





















  
  
  


  
  
    
    
      
    

    


    
    


    
    
    
    
      
      
    
    
    
    


    
    
      
      

      


      

      
      
        
        
        
      
      
      
      

    
    

    
    
      &lt;figure class=""&gt;
      
          &lt;img alt="Juggalo Robot" class="img " height="1024" src="https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/llm-coding-robot_hu_335ed2f5f6cf3413.webp" title="" width="1024" /&gt;
      
        &lt;figcaption class="caption-I-always-find-these-AI-generated-images-to-be-suspect-Say-hi-to-my-juggalo-coding-robot-angel" id="caption-I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!"&gt;
          I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!
        &lt;/figcaption&gt;
      &lt;/figure&gt;
    

  
  






  


&lt;p&gt;There are many paths for doing dev, but my case is typically one of two:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Greenfield code&lt;/li&gt;
&lt;li&gt;Legacy modern code&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will show you my process for both paths&lt;/p&gt;
&lt;h2 id="greenfield"&gt;Greenfield&lt;/h2&gt;
&lt;p&gt;I find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.&lt;/p&gt;





















  
  
  


  
  
    
    
      
    

    


    
    


    
    
    
    
      
      
    
    
    
    


    
    
      
      

      


      

      
      
        
        
        
      
      
      
      

    
    

    
    
      &lt;figure class=""&gt;
      
          &lt;img alt="Green field" class="img " height="3357" src="https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/greenfield_hu_2ad06cc996dd8386.webp" title="" width="5972" /&gt;
      
        &lt;figcaption class="caption-Technically-there-is-a-green-field-on-the-right-Leica-Q-5142016" id="caption-Technically, there is a green field on the right. Leica Q, 5/14/2016"&gt;
          Technically, there is a green field on the right. Leica Q, 5/14/2016
        &lt;/figcaption&gt;
      &lt;/figure&gt;
    

  
  







&lt;h3 id="step-1-idea-honing"&gt;Step 1: Idea honing&lt;/h3&gt;
&lt;p&gt;Use a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):&lt;/p&gt;





&lt;pre tabindex="0"&gt;&lt;code class="language-prompt"&gt;Ask me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.

Here’s the idea:

&amp;lt;IDEA&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At the end of the brainstorm (it will come to a natural conclusion):&lt;/p&gt;





&lt;pre tabindex="0"&gt;&lt;code class="language-prompt"&gt;Now that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as &lt;code&gt;spec.md&lt;/code&gt; in the repo.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id="step-2-planning"&gt;Step 2: Planning&lt;/h3&gt;
&lt;p&gt;Take the spec and pass it to a proper reasoning model (&lt;code&gt;o1*&lt;/code&gt;, &lt;code&gt;o3*&lt;/code&gt;, &lt;code&gt;r1&lt;/code&gt;):&lt;/p&gt;
&lt;p&gt;(This is the TDD prompt)&lt;/p&gt;





&lt;pre tabindex="0"&gt;&lt;code class="language-prompt"&gt;Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

&amp;lt;SPEC&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(This is the non-tdd prompt)&lt;/p&gt;





&lt;pre tabindex="0"&gt;&lt;code class="language-prompt"&gt;Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

&amp;lt;SPEC&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as &lt;code&gt;prompt_plan.md&lt;/code&gt; in the repo.&lt;/p&gt;
&lt;p&gt;I then have it output a &lt;code&gt;todo.md&lt;/code&gt; that can be checked off.&lt;/p&gt;





&lt;pre tabindex="0"&gt;&lt;code class="language-prompt"&gt;Can you make a `todo.md` that I can use as a checklist? Be thorough.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can save it as &lt;code&gt;todo.md&lt;/code&gt; in the repo.&lt;/p&gt;
&lt;p&gt;Your codegen tool should be able to check off the &lt;code&gt;todo.md&lt;/code&gt; while processing. This is good for keeping state across sessions.&lt;/p&gt;
&lt;h4 id="yay-plan"&gt;Yay. Plan!&lt;/h4&gt;
&lt;p&gt;Now you have a robust plan and documentation that will help you execute and build your project.&lt;/p&gt;
&lt;p&gt;This entire process will take maybe &lt;strong&gt;15 minutes&lt;/strong&gt;. It is pretty quick. Wild tbh.&lt;/p&gt;
&lt;h3 id="step-3-execution"&gt;Step 3: Execution&lt;/h3&gt;
&lt;p&gt;There are so many options available for execution. The success really depends on how well step 2 went.&lt;/p&gt;
&lt;p&gt;I have used this workflow with &lt;a href="https://githubnext.com/projects/copilot-workspace"&gt;github workspace&lt;/a&gt;, &lt;a href="https://aider.chat/"&gt;aider&lt;/a&gt;, &lt;a href="https://www.cursor.com/"&gt;cursor&lt;/a&gt;, &lt;a href="https://github.com/Doriandarko/claude-engineer"&gt;claude engineer&lt;/a&gt;, &lt;a href="https://sweep.dev/"&gt;sweep.dev&lt;/a&gt;, &lt;a href="https://chatgpt.com"&gt;chatgpt&lt;/a&gt;, &lt;a href="https://claude.ai"&gt;claude.ai&lt;/a&gt;, etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.&lt;/p&gt;
&lt;p&gt;I, however, prefer &lt;strong&gt;raw&lt;/strong&gt; claude and aider:&lt;/p&gt;
&lt;h3 id="claude"&gt;Claude&lt;/h3&gt;
&lt;p&gt;I essentially pair program with &lt;a href="https://claude.ai"&gt;claude.ai&lt;/a&gt; and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.&lt;/p&gt;
&lt;p&gt;I am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.&lt;/p&gt;
&lt;p&gt;I will then use a tool like &lt;a href="https://github.com/yamadashy/repomix"&gt;repomix&lt;/a&gt; to iterate when things get stuck (more about that later).&lt;/p&gt;
&lt;p&gt;The workflow is like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;set up the repo (boilerplate, uv init, cargo init, etc)&lt;/li&gt;
&lt;li&gt;paste in prompt into claude&lt;/li&gt;
&lt;li&gt;copy and paste code from claude.ai into IDE&lt;/li&gt;
&lt;li&gt;run code, run tests, etc&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;li&gt;if it works, move on to next prompt&lt;/li&gt;
&lt;li&gt;if it doesn’t work, use repomix to pass the codebase to claude to debug&lt;/li&gt;
&lt;li&gt;rinse repeat ✩₊˚.⋆☾⋆⁺₊✧&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="aider"&gt;Aider&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://aider.chat/"&gt;Aider&lt;/a&gt; is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.&lt;/p&gt;
&lt;p&gt;The workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.&lt;/p&gt;
&lt;p&gt;Aider will then “just do it” and I get to play &lt;a href="https://orteil.dashnet.org/cookieclicker/"&gt;cookie clicker&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An aside: Aider does really great benchmarking of new models for codegen in their &lt;a href="https://aider.chat/docs/leaderboards/"&gt;LLM leaderboards&lt;/a&gt;. I find it to be a really great resource for seeing how effective new models are.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Testing is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.&lt;/p&gt;
&lt;p&gt;The workflow is like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;set up the repo (boilerplate, uv init, cargo init, etc)&lt;/li&gt;
&lt;li&gt;start aider&lt;/li&gt;
&lt;li&gt;paste prompt into aider&lt;/li&gt;
&lt;li&gt;watch aider dance ♪┏(・o･)┛♪&lt;/li&gt;
&lt;li&gt;aider will run tests, or you can run app to verify&lt;/li&gt;
&lt;li&gt;if it works, move on to next prompt&lt;/li&gt;
&lt;li&gt;if it doesn’t work, Q&amp;amp;A with aider to fix&lt;/li&gt;
&lt;li&gt;rinse repeat ✩₊˚.⋆☾⋆⁺₊✧&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="results"&gt;Results&lt;/h3&gt;
&lt;p&gt;I have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.&lt;/p&gt;
&lt;p&gt;If you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.&lt;/p&gt;
&lt;p&gt;My hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.&lt;/p&gt;
&lt;h2 id="non-greenfield-iteration-incrementally"&gt;Non-greenfield: Iteration, incrementally&lt;/h2&gt;
&lt;p&gt;Sometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.&lt;/p&gt;





















  
  
  


  
  
    
    
      
    

    


    
    


    
    
    
    
      
      
    
    
    
    


    
    
      
      

      


      

      
      
        
        
        
      
      
      
      

    
    

    
    
      &lt;figure class=""&gt;
      
          &lt;img alt="a brown field" class="img " height="2302" src="https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/brownfield_hu_1c5e8f4c51a6a68a.webp" title="" width="2302" /&gt;
      
        &lt;figcaption class="caption-This-is-not-a-green-field-A-random-photo-from-my-grandfathers-camera---somewhere-in-Uganda-in-the-60s" id="caption-This is not a green field. A random photo from my grandfather&amp;rsquo;s camera - somewhere in Uganda in the 60s"&gt;
          This is not a green field. A random photo from my grandfather&amp;rsquo;s camera - somewhere in Uganda in the 60s
        &lt;/figcaption&gt;
      &lt;/figure&gt;
    

  
  







&lt;p&gt;For this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.&lt;/p&gt;
&lt;h3 id="get-context"&gt;Get context&lt;/h3&gt;
&lt;p&gt;I think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.&lt;/p&gt;
&lt;p&gt;I currently use a tool called &lt;a href="https://github.com/yamadashy/repomix"&gt;repomix&lt;/a&gt;. I have a task collection defined in my global &lt;code&gt;~/.config/mise/config.toml&lt;/code&gt; that allows me to do various things with my code base (&lt;a href="https://mise.jdx.dev/"&gt;mise rules&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Here is the LLM task list:&lt;/p&gt;





&lt;div class="highlight"&gt;&lt;pre tabindex="0"&gt;&lt;code class="language-shell"&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;LLM:clean_bundles           Generate LLM bundle output file using repomix
&lt;/span&gt;&lt;/span&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;LLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard &lt;span style="color: #66d9ef;"&gt;for&lt;/span&gt; external use
&lt;/span&gt;&lt;/span&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;LLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation
&lt;/span&gt;&lt;/span&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;LLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation
&lt;/span&gt;&lt;/span&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;LLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation
&lt;/span&gt;&lt;/span&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;LLM:generate_missing_tests  Generate missing tests &lt;span style="color: #66d9ef;"&gt;for&lt;/span&gt; code in repository content stored in output.txt using LLM generation
&lt;/span&gt;&lt;/span&gt;&lt;span style="display: flex;"&gt;&lt;span&gt;LLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I generate an &lt;code&gt;output.txt&lt;/code&gt; that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;One thing really nice about &lt;code&gt;mise&lt;/code&gt; is that the tasks can be redefined and overloaded in the working directory&amp;rsquo;s &lt;code&gt;.mise.toml&lt;/code&gt;. I can use a different tool to dump/pack the code, and as long as it generates an &lt;code&gt;output.txt&lt;/code&gt; I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the &lt;code&gt;repomix&lt;/code&gt; step to include broader ignore patterns, or just use a more effective tool to do the packing.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Once the output.txt is generated, I pass it to the &lt;a href="https://github.com/simonw/LLM"&gt;LLM&lt;/a&gt; command to do various transformations and then save those as a markdown file.&lt;/p&gt;
&lt;p&gt;Ultimately, the mise task is running this: &lt;code&gt;cat output.txt | LLM -t readme-gen &amp;gt; README.md&lt;/code&gt; or &lt;code&gt;cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen &amp;gt; code-review.md&lt;/code&gt;. This isn&amp;rsquo;t super complicated. the &lt;code&gt;LLM&lt;/code&gt; command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).&lt;/p&gt;
&lt;p&gt;For example, if I need a quick review and fix of test coverage I would do the following:&lt;/p&gt;
&lt;h4 id="claude-1"&gt;Claude&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;go to the directory where the code lives&lt;/li&gt;
&lt;li&gt;run &lt;code&gt;mise run LLM:generate_missing_tests&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;look at the generated markdown file (&lt;code&gt;missing-tests.md&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;grab the full context for the code: &lt;code&gt;mise run LLM:copy_buffer_bundle&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;paste that into claude along with the first missing test “issue”&lt;/li&gt;
&lt;li&gt;copy the generated code from claude into my ide.&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;li&gt;run tests&lt;/li&gt;
&lt;li&gt;rinse repeat ✩₊˚.⋆☾⋆⁺₊✧&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="aider-1"&gt;Aider&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;go to the directory where the code lives&lt;/li&gt;
&lt;li&gt;run aider (always make sure you are on a new branch for aider work)&lt;/li&gt;
&lt;li&gt;run &lt;code&gt;mise run LLM:generate_missing_tests&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;look at the generated markdown file (&lt;code&gt;missing-tests.md&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;paste the first missing test “issue” into aider&lt;/li&gt;
&lt;li&gt;watch aider dance ♪┏(・o･)┛♪&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;li&gt;run tests&lt;/li&gt;
&lt;li&gt;rinse repeat ✩₊˚.⋆☾⋆⁺₊✧&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.&lt;/p&gt;
&lt;h3 id="prompt-magic"&gt;Prompt magic&lt;/h3&gt;
&lt;p&gt;These quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.&lt;/p&gt;
&lt;p&gt;Here are some of my prompts that I use to dig into established code bases:&lt;/p&gt;
&lt;h4 id="code-review"&gt;Code review&lt;/h4&gt;





&lt;pre tabindex="0"&gt;&lt;code class="language-prompt"&gt;You are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.&lt;/code&gt;&lt;/pre&gt;&lt;h4 id="github-issue-generation"&gt;GitHub Issue generation&lt;/h4&gt;
&lt;p&gt;(I need to automate the actual issue posting!)&lt;/p&gt;





&lt;pre tabindex="0"&gt;&lt;code class="language-prompt"&gt;You are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues&lt;/code&gt;&lt;/pre&gt;&lt;h4 id="missing-tests"&gt;Missing tests&lt;/h4&gt;





&lt;pre tabindex="0"&gt;&lt;code class="language-prompt"&gt;You are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These prompts are pretty &lt;em&gt;old and busted&lt;/em&gt; (&amp;ldquo;boomer prompts&amp;rdquo; if I may). They need some refactoring. If you have ideas to make them better lmk.&lt;/p&gt;
&lt;h2 id="skiing-ᨒ-𖠰ᨒ-𖠰"&gt;Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰&lt;/h2&gt;
&lt;p&gt;When I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”&lt;/p&gt;
&lt;p&gt;For some reason I say &amp;ldquo;over my skis&amp;rdquo; a lot when talking about LLMs. I don&amp;rsquo;t know why. It resonates with me. Maybe it&amp;rsquo;s because it is beautiful smooth powder skiing, and then all of a sudden you are like &amp;ldquo;WHAT THE FUCK IS GOING ON!,&amp;rdquo; and are completely lost and suddenly fall off a cliff.&lt;/p&gt;
&lt;p&gt;I find that using a &lt;strong&gt;planning step&lt;/strong&gt; (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.&lt;/p&gt;
&lt;p&gt;Regardless, I still do find myself &lt;strong&gt;over my skis&lt;/strong&gt; quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id="i-am-so-lonely-"&gt;I am so lonely (｡•́︿•̀｡)&lt;/h2&gt;
&lt;p&gt;My main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all &lt;em&gt;single player mode&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.&lt;/p&gt;
&lt;p&gt;I really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.&lt;/p&gt;
&lt;p&gt;GET TO WORK!&lt;/p&gt;
&lt;h2 id="ⴵ-time-ⴵ"&gt;ⴵ Time ⴵ&lt;/h2&gt;
&lt;p&gt;All this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.&lt;/p&gt;





















  
  
  


  
  
    
    
      
    

    


    
    


    
    
    
    
      
      
    
    
    
    


    
    
      
      

      


      

      
      
        
        
        
      
      
      
      

    
    

    
    
      &lt;figure class=""&gt;
      
          &lt;img alt="Printing" class="img " height="457" src="https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/apple-print-shop-printing_hu_279a40ac58332186.webp" title="" width="600" /&gt;
      
        &lt;figcaption class="caption-I-remember-this-like-it-was-yesterday" id="caption-I remember this like it was yesterday"&gt;
          I remember this like it was yesterday
        &lt;/figcaption&gt;
      &lt;/figure&gt;
    

  
  







&lt;p&gt;I have changed how I work enough to start incorporating some practice that will try and eat the waiting time:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I start the “brainstorming” process for another project&lt;/li&gt;
&lt;li&gt;I listen to records&lt;/li&gt;
&lt;li&gt;I play &lt;a href="https://orteil.dashnet.org/cookieclicker/"&gt;cookie clicker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;I talk with friends and robots&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is awesome to be able to hack like this. Hack Hack Hack. I can&amp;rsquo;t think of another time I have been this productive in code.&lt;/p&gt;
&lt;h2 id="haterade--_-"&gt;Haterade ╭∩╮( •̀_•́ )╭∩╮&lt;/h2&gt;
&lt;p&gt;A lot of my friends are like &amp;ldquo;fuck LLMs. They are terrible at everything.&amp;rdquo; I don&amp;rsquo;t mind this POV. I don&amp;rsquo;t share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But&amp;hellip; the code must flow. Right&amp;hellip; sigh.&lt;/p&gt;
&lt;p&gt;If you are open to learning more, but don&amp;rsquo;t want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick&amp;rsquo;s book about LLMs and how they can be used: &lt;a href="https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/"&gt;&lt;strong&gt;Co-Intelligence: Living and Working with AI.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.&lt;/p&gt;
&lt;p&gt;If you are skeptical, but a bit curious - feel free to hit me up and let&amp;rsquo;s talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;thanks to &lt;a href="https://derek.broox.com"&gt;Derek&lt;/a&gt;, &lt;a href="https://nocruft.com/"&gt;Kanno&lt;/a&gt;, &lt;a href="https://fsck.com"&gt;Obra&lt;/a&gt;, and &lt;a href="https://thinks.lol/"&gt;Erik&lt;/a&gt; for taking a look at this post and suggesting edits. I appreciate it.&lt;/em&gt;&lt;/p&gt;

                                &lt;figure&gt;
                                    &lt;img alt="apple-print-shop-printing.png" height="457" src="https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/apple-print-shop-printing.png" width="600" /&gt;
                                    
                                &lt;/figure&gt;
                                &lt;figure&gt;
                                    &lt;img alt="brownfield.jpg" height="2302" src="https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/brownfield.jpg" width="2302" /&gt;
                                    
                                &lt;/figure&gt;
                                &lt;figure&gt;
                                    &lt;img alt="greenfield.jpg" height="3357" src="https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/greenfield.jpg" width="5972" /&gt;
                                    
                                &lt;/figure&gt;
                                &lt;figure&gt;
                                    &lt;img alt="llm-coding-robot.webp" height="1024" src="https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/llm-coding-robot.webp" width="1024" /&gt;
                                    
                                &lt;/figure&gt;
                        
                        &lt;hr /&gt;
                        &lt;p&gt;Thank you for using RSS. I appreciate you. &lt;a href="mailto:harper&amp;#64;modest.com"&gt;Email me&lt;/a&gt;&lt;/p&gt;</description><pubDate>Sun, 16 Feb 2025 18:00:00 -0500</pubDate></item></channel></rss>